{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color spaces\n",
    "\n",
    "You can convert BGR to every format and make inverse conversion. But you cannot do Gray to HSV directly, same for other type. You always have to pass by BGR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv.imread('Resources/Photos/park.jpg')\n",
    "\n",
    "# 1. converting image to grey scale\n",
    "grey = cv.cvtColor(image,cv.COLOR_BGR2GRAY) \n",
    "\n",
    "# 2. BGR to HSV\n",
    "hsv = cv.cvtColor(image,cv.COLOR_BGR2HSV) \n",
    "\n",
    "# 3. BGR to L*a*b\n",
    "lab = cv.cvtColor(image,cv.COLOR_BGR2LAB) \n",
    "\n",
    "# 4. BGR to RGB\n",
    "\"\"\" This is the format usually use (with matplotlib for exemple\"\"\"\n",
    "hsv = cv.cvtColor(image,cv.COLOR_BGR2RGB) \n",
    "\n",
    "# display\n",
    "cv.imshow('Park',image) \n",
    "cv.imshow('Park grey',grey) \n",
    "cv.imshow('Park hsv',hsv) \n",
    "cv.imshow('Park lab',lab) \n",
    "\n",
    "# wait time for a key to be press\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Channels\n",
    "\n",
    "Split an image in each channel. From exemple to BGR to Blue, Green and Red image.\n",
    "\n",
    "It shows the pixel intensity of each channel. You will see the image in grey scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv.imread('Resources/Photos/park.jpg')\n",
    "\n",
    "# 1. split image\n",
    "b,g,r = cv.split(image)\n",
    "\n",
    "# 2. rebuild image\n",
    "merge = cv.merge([b,g,r])\n",
    "\n",
    "# 3. create split image with good color (not in grey)\n",
    "blank = np.zeros(image.shape[:2],dtype='uint8')\n",
    "blue = cv.merge([b,blank,blank])\n",
    "green = cv.merge([blank,g,blank])\n",
    "red = cv.merge([blank,blank,r])\n",
    "\n",
    "# display\n",
    "cv.imshow('Park',image) \n",
    "# cv.imshow('Park blue',b) \n",
    "# cv.imshow('Park green',g) \n",
    "# cv.imshow('Park red',r) \n",
    "# cv.imshow('Park merge',merge) \n",
    "cv.imshow('Park blue',blue) \n",
    "cv.imshow('Park green',green) \n",
    "cv.imshow('Park red',red) \n",
    "\n",
    "# wait time for a key to be press\n",
    "cv.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blurring\n",
    "\n",
    "\n",
    "- Blurring : smoothing image using a slicing window \n",
    "- window : specifique portion of the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv.imread('Resources/Photos/park.jpg')\n",
    "\n",
    "# averaging \n",
    "\"\"\"get the average pixels intensity of a given window and use this for each pixel in that window\"\"\"\n",
    "average = cv.blur(image,(7,7))\n",
    "\n",
    "# gaussian \n",
    "\"\"\"each pixel of a window has a weigth\"\"\"\n",
    "gauss = cv.GaussianBlur(image,ksize = (7,7),sigmaX = 0)\n",
    "\n",
    "# median \n",
    "\"\"\"get the meadian pixels intensity of a given window and use this for each pixel in that window\n",
    "More effective to reduce noise\"\"\"\n",
    "median = cv.medianBlur(image,ksize = 7 ) # window is obligatory 3*3\n",
    "\n",
    "# bilateral \n",
    "\"\"\"blur the image but retains the edges\n",
    "Most effective\n",
    "- d = diameter windows\n",
    "- sigmaColor = larger value means more color are consider\n",
    "- sigmaSpace = larger value means that pixels further out from the central one will influrence the blurring\"\"\"\n",
    "bilateral = cv.bilateralFilter(image,d = 5, sigmaColor = 15,sigmaSpace = 15)\n",
    "\n",
    "# display\n",
    "cv.imshow('Park',image) \n",
    "cv.imshow('Park average',average) \n",
    "cv.imshow('Park gaussian',gauss) \n",
    "cv.imshow('Park median',median) \n",
    "cv.imshow('Park bilateral',bilateral) \n",
    "\n",
    "# wait time for a key to be press\n",
    "cv.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bitwise operations\n",
    "\n",
    "A pixel is turn off is it has a value of 0 and turn on if its value is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blank = np.zeros((400,400),dtype='uint8')\n",
    "\n",
    "# create shapes \n",
    "rectangle = cv.rectangle(blank.copy(),(30,30),(370,370),255,-1)\n",
    "circle = cv.circle(blank.copy(),(200,200),200,255,-1)\n",
    "\n",
    "# Bitwise AND\n",
    "\"\"\"Return the intersection of two images\"\"\"\n",
    "bitwise_and = cv.bitwise_and(rectangle,circle)\n",
    "\n",
    "# Bitwise OR\n",
    "\"\"\"Return the union of two images\"\"\"\n",
    "bitwise_or = cv.bitwise_or(rectangle,circle)\n",
    "\n",
    "# Bitwise XOR\n",
    "\"\"\"Return the non intersection of two images\"\"\"\n",
    "bitwise_xor = cv.bitwise_xor(rectangle,circle)\n",
    "\n",
    "# Bitwise NOT\n",
    "\"\"\"Inverse the binary color\"\"\"\n",
    "bitwise_not = cv.bitwise_not(rectangle)\n",
    "\n",
    "# display\n",
    "# cv.imshow('Rectangle',rectangle) \n",
    "# cv.imshow('Circle',circle) \n",
    "cv.imshow('Bitwise AND',bitwise_and) \n",
    "cv.imshow('Bitwise OR',bitwise_or) \n",
    "cv.imshow('Bitwise XOR',bitwise_xor) \n",
    "cv.imshow('Rectangle NOT',bitwise_not) \n",
    "\n",
    "# wait time for a key to be press\n",
    "cv.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv.imread('Resources/Photos/cats.jpg')\n",
    "\n",
    "# create mask\n",
    "\"\"\" The mask need to be the same size as the image even if we want to mask just a part\"\"\"\n",
    "blank = np.zeros(image.shape[:2],dtype='uint8')\n",
    "mask = cv.circle(blank.copy(),(image.shape[1]//2,image.shape[0]//2),100,255,-1)\n",
    "\n",
    "# masked image\n",
    "masked = cv.bitwise_and(image,image,mask=mask)\n",
    "\n",
    "# other shapes\n",
    "cercle = circle = cv.circle(blank.copy(),(image.shape[1]//2,image.shape[0]//2),100,255,-1)\n",
    "rectangle = cv.rectangle(blank.copy(),(30,30),(370,370),255,-1)\n",
    "shape = cv.bitwise_and(rectangle,circle)\n",
    "shape_masked = cv.bitwise_and(image,image,mask=shape)\n",
    "\n",
    "# display\n",
    "cv.imshow('Cats',image) \n",
    "cv.imshow('Masked cats',masked) \n",
    "cv.imshow('Masked shape cats',shape_masked) \n",
    "\n",
    "# wait time for a key to be press\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historigram computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding/Binarizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
